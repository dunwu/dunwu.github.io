import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as d,o as t,c as o,a as e,b as s,d as n,e as i}from"./app-afc5da4f.js";const c={},l=i('<h1 id="缓存夺命连环问" tabindex="-1"><a class="header-anchor" href="#缓存夺命连环问" aria-hidden="true">#</a> 缓存夺命连环问</h1><h2 id="为什么要用缓存" tabindex="-1"><a class="header-anchor" href="#为什么要用缓存" aria-hidden="true">#</a> 为什么要用缓存？</h2><p>用缓存，主要有两个用途：<strong>高性能</strong>、<strong>高并发</strong>。</p><h3 id="高性能" tabindex="-1"><a class="header-anchor" href="#高性能" aria-hidden="true">#</a> 高性能</h3><p>假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？</p><p>缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。</p><p>就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。</p><h3 id="高并发" tabindex="-1"><a class="header-anchor" href="#高并发" aria-hidden="true">#</a> 高并发</h3><p>mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 <code>2000QPS</code> 也开始容易报警了。</p><p>所以要是你有个系统，高峰期一秒钟过来的请求有 1 万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 <code>key-value</code> 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。</p><blockquote><p>缓存是走内存的，内存天然就支撑高并发。</p></blockquote><h2 id="用了缓存之后会有什么不良后果" tabindex="-1"><a class="header-anchor" href="#用了缓存之后会有什么不良后果" aria-hidden="true">#</a> 用了缓存之后会有什么不良后果？</h2><p>常见的缓存问题有以下几个：</p>',13),p={href:"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md",target:"_blank",rel:"noopener noreferrer"},h={href:"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-caching-avalanche-and-caching-penetration.md",target:"_blank",rel:"noopener noreferrer"},u={href:"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-cas.md",target:"_blank",rel:"noopener noreferrer"},g=e("p",null,"后面再详细说明。",-1),m=e("h2",{id:"redis-和-memcached-有啥区别",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#redis-和-memcached-有啥区别","aria-hidden":"true"},"#"),s(" redis 和 memcached 有啥区别？")],-1),v=e("p",null,"redis 支持复杂的数据结构",-1),b={href:"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-data-types.md",target:"_blank",rel:"noopener noreferrer"},k=i(`<p>redis 原生支持集群模式</p><p>在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p><p>性能对比</p><p>由于 redis 只使用<strong>单核</strong>，而 memcached 可以使用<strong>多核</strong>，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。</p><h2 id="为啥-redis-单线程模型也能效率这么高" tabindex="-1"><a class="header-anchor" href="#为啥-redis-单线程模型也能效率这么高" aria-hidden="true">#</a> 为啥 redis 单线程模型也能效率这么高？</h2><h3 id="redis-的线程模型" tabindex="-1"><a class="header-anchor" href="#redis-的线程模型" aria-hidden="true">#</a> redis 的线程模型</h3><p>redis 内部使用文件事件处理器 <code>file event handler</code>，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。</p><p>文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 socket</li><li>IO 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。</p><p>来看客户端与 redis 的一次通信过程：</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/redis-single-thread-model.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。</p><p>首先，redis 服务端进程初始化的时候，会将 server socket 的 <code>AE_READABLE</code> 事件与连接应答处理器关联。</p><p>客户端 socket01 向 redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 <code>AE_READABLE</code> 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给<strong>连接应答处理器</strong>。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 <code>AE_READABLE</code> 事件与命令请求处理器关联。</p><p>假设此时客户端发送了一个 <code>set key value</code> 请求，此时 redis 中的 socket01 会产生 <code>AE_READABLE</code> 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 <code>AE_READABLE</code> 事件，由于前面 socket01 的 <code>AE_READABLE</code> 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 <code>key value</code> 并在自己内存中完成 <code>key value</code> 的设置。操作完成后，它会将 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器关联。</p><p>如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 <code>AE_WRITABLE</code> 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 <code>ok</code>，之后解除 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器的关联。</p><p>这样便完成了一次通信。</p><h3 id="为啥-redis-单线程模型也能效率这么高-1" tabindex="-1"><a class="header-anchor" href="#为啥-redis-单线程模型也能效率这么高-1" aria-hidden="true">#</a> 为啥 redis 单线程模型也能效率这么高?</h3><ul><li>纯内存操作。</li><li>核心是基于非阻塞的 IO 多路复用机制。</li><li>C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。</li><li>单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。</li></ul><h2 id="redis-有哪些数据类型" tabindex="-1"><a class="header-anchor" href="#redis-有哪些数据类型" aria-hidden="true">#</a> Redis 有哪些数据类型</h2><p>redis 主要有以下几种数据类型：</p><ul><li>string</li><li>hash</li><li>list</li><li>set</li><li>sorted set</li></ul><h3 id="string" tabindex="-1"><a class="header-anchor" href="#string" aria-hidden="true">#</a> string</h3><p>这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>set college szu
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="hash" tabindex="-1"><a class="header-anchor" href="#hash" aria-hidden="true">#</a> hash</h3><p>这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是<strong>这个对象没嵌套其他的对象</strong>）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的<strong>某个字段</strong>。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>hset person name bingo
hset person age <span class="token number">20</span>
hset person <span class="token function">id</span> <span class="token number">1</span>
hget person name
person <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&quot;name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;bingo&quot;</span>,
    <span class="token string">&quot;age&quot;</span><span class="token builtin class-name">:</span> <span class="token number">20</span>,
    <span class="token string">&quot;id&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="list" tabindex="-1"><a class="header-anchor" href="#list" aria-hidden="true">#</a> list</h3><p>list 是有序列表，这个可以玩儿出很多花样。</p><p>比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p><p>比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code># 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。
lrange mylist 0 -1
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>lpush mylist 1
lpush mylist 2
lpush mylist 3 4 5

# 1
rpop mylist
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="set" tabindex="-1"><a class="header-anchor" href="#set" aria-hidden="true">#</a> set</h3><p>set 是无序集合，自动去重。</p><p>直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重。</p><p>可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。</p><p>把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>#-------操作一个set-------
# 添加元素
sadd mySet 1

# 查看全部元素
smembers mySet

# 判断是否包含某个值
sismember mySet 3

# 删除某个/些元素
srem mySet 1
srem mySet 2 4

# 查看元素个数
scard mySet

# 随机删除一个元素
spop mySet

#-------操作多个set-------
# 将一个set的元素移动到另外一个set
smove yourSet mySet 2

# 求两set的交集
sinter yourSet mySet

# 求两set的并集
sunion yourSet mySet

# 求在yourSet中而不在mySet中的元素
sdiff yourSet mySet
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="sorted-set" tabindex="-1"><a class="header-anchor" href="#sorted-set" aria-hidden="true">#</a> sorted set</h3><p>sorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>zadd board 85 zhangsan
zadd board 72 lisi
zadd board 96 wangwu
zadd board 63 zhaoliu

# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）
zrevrange board 0 3

# 获取某用户的排名
zrank board zhaoliu
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="如何保证-redis-的高并发和高可用-redis-的主从复制原理能介绍一下么-redis-的哨兵原理能介绍一下么" tabindex="-1"><a class="header-anchor" href="#如何保证-redis-的高并发和高可用-redis-的主从复制原理能介绍一下么-redis-的哨兵原理能介绍一下么" aria-hidden="true">#</a> 如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？</h2><p>如果你用 redis 缓存技术的话，肯定要考虑如何用 redis 来加多台机器，保证 redis 是高并发的，还有就是如何让 redis 保证自己不是挂掉以后就直接死掉了，即 redis 高可用。</p><p>由于此节内容较多，因此，会分为两个小节进行讲解。</p>`,48),f={href:"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-master-slave.md",target:"_blank",rel:"noopener noreferrer"},y={href:"https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-sentinel.md",target:"_blank",rel:"noopener noreferrer"},x=i(`<p>redis 实现<strong>高并发</strong>主要依靠<strong>主从架构</strong>，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万 QPS，多从用来查询数据，多个从实例可以提供每秒 10w 的 QPS。</p><p>如果想要在实现高并发的同时，容纳大量的数据，那么就需要 redis 集群，使用 redis 集群之后，可以提供每秒几十万的读写并发。</p><p>redis 高可用，如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可以进行主备切换。</p><h2 id="redis-的过期策略都有哪些-内存淘汰机制都有哪些-手写一下-lru-代码实现" tabindex="-1"><a class="header-anchor" href="#redis-的过期策略都有哪些-内存淘汰机制都有哪些-手写一下-lru-代码实现" aria-hidden="true">#</a> redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？</h2><h3 id="redis-过期策略" tabindex="-1"><a class="header-anchor" href="#redis-过期策略" aria-hidden="true">#</a> redis 过期策略</h3><p>redis 过期策略是：<strong>定期删除+惰性删除</strong>。</p><p>所谓<strong>定期删除</strong>，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。</p><p>假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的<strong>灾难</strong>。实际上 redis 是每隔 100ms <strong>随机抽取</strong>一些 key 来检查和删除的。</p><p>但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。</p><blockquote><p>获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。</p></blockquote><p>但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？</p><p>答案是：<strong>走内存淘汰机制</strong>。</p><h3 id="内存淘汰机制" tabindex="-1"><a class="header-anchor" href="#内存淘汰机制" aria-hidden="true">#</a> 内存淘汰机制</h3><p>redis 内存淘汰机制有以下几个：</p><ul><li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li><li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，移除最近最少使用的 key（这个是<strong>最常用</strong>的）。</li><li>allkeys-random：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li><li>volatile-lru：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，移除最近最少使用的 key（这个一般不太合适）。</li><li>volatile-random：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，<strong>随机移除</strong>某个 key。</li><li>volatile-ttl：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，有<strong>更早过期时间</strong>的 key 优先移除。</li></ul><h3 id="手写一个-lru-算法" tabindex="-1"><a class="header-anchor" href="#手写一个-lru-算法" aria-hidden="true">#</a> 手写一个 LRU 算法</h3><p>你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。</p><p>不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token keyword">class</span> <span class="token class-name">LRUCache</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">LinkedHashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
    <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token keyword">int</span> <span class="token constant">CACHE_SIZE</span><span class="token punctuation">;</span>

    <span class="token doc-comment comment">/**
     * 传递进来最多能缓存多少数据
     *
     * <span class="token keyword">@param</span> <span class="token parameter">cacheSize</span> 缓存大小
     */</span>
    <span class="token keyword">public</span> <span class="token class-name">LRUCache</span><span class="token punctuation">(</span><span class="token keyword">int</span> cacheSize<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">ceil</span><span class="token punctuation">(</span>cacheSize <span class="token operator">/</span> <span class="token number">0.75</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.75f</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token constant">CACHE_SIZE</span> <span class="token operator">=</span> cacheSize<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">protected</span> <span class="token keyword">boolean</span> <span class="token function">removeEldestEntry</span><span class="token punctuation">(</span><span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> eldest<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。</span>
        <span class="token keyword">return</span> <span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token constant">CACHE_SIZE</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="redis-集群模式的工作原理能说一下么-在集群模式下-redis-的-key-是如何寻址的-分布式寻址都有哪些算法-了解一致性-hash-算法吗" tabindex="-1"><a class="header-anchor" href="#redis-集群模式的工作原理能说一下么-在集群模式下-redis-的-key-是如何寻址的-分布式寻址都有哪些算法-了解一致性-hash-算法吗" aria-hidden="true">#</a> redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？</h2><p>在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得<strong>借助一些中间件</strong>来实现，比如说有 <code>codis</code>，或者 <code>twemproxy</code>，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。</p><p>这两年，redis 不断在发展，redis 也不断有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis 实例，每个实例存储一部分的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。</p><p>现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis 集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用 codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。</p><p>如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。</p><p>redis cluster，主要是针对<strong>海量数据+高并发+高可用</strong>的场景。redis cluster 支撑 N 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。</p><h3 id="面试题剖析" tabindex="-1"><a class="header-anchor" href="#面试题剖析" aria-hidden="true">#</a> 面试题剖析</h3><h3 id="redis-cluster-介绍" tabindex="-1"><a class="header-anchor" href="#redis-cluster-介绍" aria-hidden="true">#</a> redis cluster 介绍</h3><ul><li>自动将数据进行分片，每个 master 上放一部分数据</li><li>提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的</li></ul><p>在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加 1w 的端口号，比如 16379。</p><p>16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，<code>gossip</code> 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。</p><h3 id="节点间的内部通信机制" tabindex="-1"><a class="header-anchor" href="#节点间的内部通信机制" aria-hidden="true">#</a> 节点间的内部通信机制</h3><h4 id="基本通信原理" tabindex="-1"><a class="header-anchor" href="#基本通信原理" aria-hidden="true">#</a> 基本通信原理</h4><p>集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。</p><p><strong>集中式</strong>是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 <code>storm</code>。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/zookeeper-centralized-storage.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>redis 维护集群元数据采用另一个方式， <code>gossip</code> 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/redis-gossip.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p><strong>集中式</strong>的<strong>好处</strong>在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；<strong>不好</strong>在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。</p><p>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</p><ul><li>10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 <code>ping</code> 消息，同时其它几个节点接收到 <code>ping</code> 之后返回 <code>pong</code>。</li><li>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</li></ul><h4 id="gossip-协议" tabindex="-1"><a class="header-anchor" href="#gossip-协议" aria-hidden="true">#</a> gossip 协议</h4><p>gossip 协议包含多种消息，包含 <code>ping</code>,<code>pong</code>,<code>meet</code>,<code>fail</code> 等等。</p><ul><li>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。</li></ul><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>redis-trib.rb add-node
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。</p><ul><li>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</li><li>pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。</li><li>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。</li></ul><h4 id="ping-消息深入" tabindex="-1"><a class="header-anchor" href="#ping-消息深入" aria-hidden="true">#</a> ping 消息深入</h4><p>ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。</p><p>每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 <code>cluster_node_timeout / 2</code>，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 <code>cluster_node_timeout</code> 可以调节，如果调得比较大，那么会降低 ping 的频率。</p><p>每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 <code>3</code> 个其它节点的信息，最多包含 <code>总节点数减 2</code> 个其它节点的信息。</p><h3 id="分布式寻址算法" tabindex="-1"><a class="header-anchor" href="#分布式寻址算法" aria-hidden="true">#</a> 分布式寻址算法</h3><ul><li>hash 算法（大量缓存重建）</li><li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li><li>redis cluster 的 hash slot 算法</li></ul><h4 id="hash-算法" tabindex="-1"><a class="header-anchor" href="#hash-算法" aria-hidden="true">#</a> hash 算法</h4><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致<strong>大部分的请求过来，全部无法拿到有效的缓存</strong>，导致大量的流量涌入数据库。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/hash.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h4 id="一致性-hash-算法" tabindex="-1"><a class="header-anchor" href="#一致性-hash-算法" aria-hidden="true">#</a> 一致性 hash 算法</h4><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p><p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p><p>在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。</p><p>燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/consistent-hashing-algorithm.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h4 id="redis-cluster-的-hash-slot-算法" tabindex="-1"><a class="header-anchor" href="#redis-cluster-的-hash-slot-算法" aria-hidden="true">#</a> redis cluster 的 hash slot 算法</h4><p>redis cluster 有固定的 <code>16384</code> 个 hash slot，对每个 <code>key</code> 计算 <code>CRC16</code> 值，然后对 <code>16384</code> 取模，可以获取 key 对应的 hash slot。</p><p>redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 <code>hash tag</code> 来实现。</p><p>任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/hash-slot.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="redis-cluster-的高可用与主备切换原理" tabindex="-1"><a class="header-anchor" href="#redis-cluster-的高可用与主备切换原理" aria-hidden="true">#</a> redis cluster 的高可用与主备切换原理</h3><p>redis cluster 的高可用的原理，几乎跟哨兵是类似的。</p><h4 id="判断节点宕机" tabindex="-1"><a class="header-anchor" href="#判断节点宕机" aria-hidden="true">#</a> 判断节点宕机</h4><p>如果一个节点认为另外一个节点宕机，那么就是 <code>pfail</code>，<strong>主观宕机</strong>。如果多个节点都认为另外一个节点宕机了，那么就是 <code>fail</code>，<strong>客观宕机</strong>，跟哨兵的原理几乎一样，sdown，odown。</p><p>在 <code>cluster-node-timeout</code> 内，某个节点一直没有返回 <code>pong</code>，那么就被认为 <code>pfail</code>。</p><p>如果一个节点认为某个节点 <code>pfail</code> 了，那么会在 <code>gossip ping</code> 消息中，<code>ping</code> 给其他节点，如果<strong>超过半数</strong>的节点都认为 <code>pfail</code> 了，那么就会变成 <code>fail</code>。</p><h4 id="从节点过滤" tabindex="-1"><a class="header-anchor" href="#从节点过滤" aria-hidden="true">#</a> 从节点过滤</h4><p>对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。</p><p>检查每个 slave node 与 master node 断开连接的时间，如果超过了 <code>cluster-node-timeout * cluster-slave-validity-factor</code>，那么就<strong>没有资格</strong>切换成 <code>master</code>。</p><h4 id="从节点选举" tabindex="-1"><a class="header-anchor" href="#从节点选举" aria-hidden="true">#</a> 从节点选举</h4><p>每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p><p>所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node<code>（N/2 + 1）</code>都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。</p><p>从节点执行主备切换，从节点切换为主节点。</p><h4 id="与哨兵比较" tabindex="-1"><a class="header-anchor" href="#与哨兵比较" aria-hidden="true">#</a> 与哨兵比较</h4><p>整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。</p><h2 id="如何保证缓存与数据库的双写一致性" tabindex="-1"><a class="header-anchor" href="#如何保证缓存与数据库的双写一致性" aria-hidden="true">#</a> 如何保证缓存与数据库的双写一致性？</h2><p>一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统<strong>不是严格要求</strong> “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：<strong>读请求和写请求串行化</strong>，串到一个<strong>内存队列</strong>里去。</p><p>串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p><h3 id="cache-aside-pattern" tabindex="-1"><a class="header-anchor" href="#cache-aside-pattern" aria-hidden="true">#</a> Cache Aside Pattern</h3><p>最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。</p><ul><li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li><li>更新的时候，<strong>先更新数据库，然后再删除缓存</strong>。</li></ul><p><strong>为什么是删除缓存，而不是更新缓存？</strong></p><p>原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。</p><p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</p><p>另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于<strong>比较复杂的缓存数据计算的场景</strong>，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，<strong>这个缓存到底会不会被频繁访问到？</strong></p><p>举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有<strong>大量的冷数据</strong>。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。<strong>用到缓存才去算缓存。</strong></p><p>其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。</p><h3 id="最初级的缓存不一致问题及解决方案" tabindex="-1"><a class="header-anchor" href="#最初级的缓存不一致问题及解决方案" aria-hidden="true">#</a> 最初级的缓存不一致问题及解决方案</h3><p>问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/redis-junior-inconsistent.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。</p><h3 id="比较复杂的数据不一致问题分析" tabindex="-1"><a class="header-anchor" href="#比较复杂的数据不一致问题分析" aria-hidden="true">#</a> 比较复杂的数据不一致问题分析</h3><p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，<strong>查到了修改前的旧数据</strong>，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了...</p><p><strong>为什么上亿流量高并发场景下，缓存会出现这个问题？</strong></p><p>只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就<strong>可能会出现上述的数据库+缓存不一致的情况</strong>。</p><p><strong>解决方案如下：</strong></p><p>更新数据的时候，根据<strong>数据的唯一标识</strong>，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。</p><p>一个队列对应一个工作线程，每个工作线程<strong>串行</strong>拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p><p>这里有一个<strong>优化点</strong>，一个队列中，其实<strong>多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p><p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p><p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。</p><p>高并发的场景下，该解决方案要注意的问题：</p><ul><li>读请求长时阻塞</li></ul><p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。</p><p>该解决方案，最大的风险点在于说，<strong>可能数据更新很频繁</strong>，导致队列中积压了大量更新操作在里面，然后<strong>读请求会发生大量的超时</strong>，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。</p><p>另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要<strong>部署多个服务</strong>，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每隔库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致<strong>读请求的长时阻塞</strong>。</p><p>一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。</p><p><strong>如果一个内存队列中可能积压的更新操作特别多</strong>，那么你就要<strong>加机器</strong>，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。</p><p>其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。</p><p>我们来<strong>实际粗略测算一下</strong>。</p><p>如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。</p><p>经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。</p><ul><li>读请求并发量过高</li></ul><p>这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。</p><p>但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。</p><ul><li>多服务实例部署的请求路由</li></ul><p>可能这个服务部署了多个实例，那么必须<strong>保证</strong>说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器<strong>路由到相同的服务实例上</strong>。</p><p>比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。</p><ul><li>热点商品的路由问题，导致请求的倾斜</li></ul><p>万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。</p><h2 id="了解什么是-redis-的雪崩、穿透和击穿-redis-崩溃之后会怎么样-系统该如何应对这种情况-如何处理-redis-的穿透" tabindex="-1"><a class="header-anchor" href="#了解什么是-redis-的雪崩、穿透和击穿-redis-崩溃之后会怎么样-系统该如何应对这种情况-如何处理-redis-的穿透" aria-hidden="true">#</a> 了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？</h2><h3 id="缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存雪崩" aria-hidden="true">#</a> 缓存雪崩</h3><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。</p><p>这就是缓存雪崩。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/redis-caching-avalanche.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。</p><p>缓存雪崩的事前事中事后的解决方案如下。</p><ul><li>事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。</li><li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li><li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/redis-caching-avalanche-solution.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。</p><p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<strong>走降级</strong>！可以返回一些默认的值，或者友情提示，或者空白的值。</p><p>好处：</p><ul><li>数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。</li><li>只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。</li><li>只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次。</li></ul><h3 id="缓存穿透" tabindex="-1"><a class="header-anchor" href="#缓存穿透" aria-hidden="true">#</a> 缓存穿透</h3><p>对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p><p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p><p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/redis-caching-penetration.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 <code>set -999 UNKNOWN</code>。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</p><h3 id="缓存击穿" tabindex="-1"><a class="header-anchor" href="#缓存击穿" aria-hidden="true">#</a> 缓存击穿</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p><p>解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。</p><h2 id="redis-的并发竞争问题是什么-如何解决这个问题-了解-redis-事务的-cas-方案吗" tabindex="-1"><a class="header-anchor" href="#redis-的并发竞争问题是什么-如何解决这个问题-了解-redis-事务的-cas-方案吗" aria-hidden="true">#</a> redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？</h2><p>某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。</p><figure><img src="https://github.com/doocs/advanced-java/blob/master/images/zookeeper-distributed-lock.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。</p><p>每次要<strong>写之前，先判断</strong>一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。</p><h2 id="生产环境中的-redis-是怎么部署的" tabindex="-1"><a class="header-anchor" href="#生产环境中的-redis-是怎么部署的" aria-hidden="true">#</a> 生产环境中的 redis 是怎么部署的？</h2><p>redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。</p><p>机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是 10g 内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。</p><p>5 台机器对外提供读写，一共有 50g 内存。</p><p>因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。</p><p>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。</p><p>其实大型的公司，会有基础架构的 team 负责缓存集群的运维。</p>`,160);function _(E,A){const a=d("ExternalLinkIcon");return t(),o("div",null,[l,e("ul",null,[e("li",null,[e("a",p,[s("缓存与数据库双写不一致"),n(a)])]),e("li",null,[e("a",h,[s("缓存雪崩、缓存穿透"),n(a)])]),e("li",null,[e("a",u,[s("缓存并发竞争"),n(a)])])]),g,m,v,e("p",null,[s("redis 相比 memcached 来说，拥有"),e("a",b,[s("更多的数据结构"),n(a)]),s("，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。")]),k,e("ul",null,[e("li",null,[e("a",f,[s("redis 主从架构"),n(a)])]),e("li",null,[e("a",y,[s("redis 基于哨兵实现高可用"),n(a)])])]),x])}const j=r(c,[["render",_],["__file","index.html.vue"]]);export{j as default};
