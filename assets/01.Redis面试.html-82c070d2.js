import{_ as t}from"./plugin-vue_export-helper-c27b6911.js";import{r,o as l,c as o,a as s,b as e,d as a,e as i}from"./app-103fb7a1.js";const d={},p=i('<h1 id="redis-面试" tabindex="-1"><a class="header-anchor" href="#redis-面试" aria-hidden="true">#</a> Redis 面试</h1><h2 id="redis-简介" tabindex="-1"><a class="header-anchor" href="#redis-简介" aria-hidden="true">#</a> Redis 简介</h2><h3 id="什么是-redis" tabindex="-1"><a class="header-anchor" href="#什么是-redis" aria-hidden="true">#</a> 什么是 Redis</h3><p>【问题】</p><ul><li>什么是 Redis？</li><li>Redis 有什么特性？</li><li>Redis 有什么功能？</li></ul><p>【解答】</p><p><strong>Redis 是一种内存数据库</strong>，对数据的读写操作都是在内存中完成。因此其<strong>读写速度非常快</strong>，常用于<strong>缓存，消息队列、分布式锁等场景</strong>。</p><ul><li><strong>高性能</strong> – Redis 的数据读写都是在内存中完成，因此性能极高。</li><li><strong>高并发</strong> - Redis 的读速度约为 10w+ QPS，写的速度约为 8w+ TPS，将近是 Mysql 的 10 倍。</li></ul><p><strong>Redis 支持多种数据类型</strong>，如：String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理空间）、Stream（流）。Redis 对数据类型的操作都是<strong>原子性</strong>的，因为执行命令由单线程负责的，不存在并发竞争的问题。</p><p><strong>Redis 的读写采用单线程模型</strong>，因此，其操作天然就具有<strong>原子性</strong>。</p><p>Redis 支持两种持久化策略：RDB 和 AOF。</p><p>Redis 支持过期删除和内存淘汰，因此常被用于作为缓存。</p><p>Redis 有多种高可用方案：<strong>主从复制</strong>模式、<strong>哨兵</strong>模式、<strong>集群</strong>模式。</p><p>Redis 支持很多丰富的特性，如：<strong>事务</strong> 、<strong>Lua 脚本</strong>、<strong>发布订阅</strong>等等。</p><figure><img src="https://architecturenotes.co/content/images/size/w2400/2022/08/Redis-v2-01-1.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',15),c={href:"https://architecturenotes.co/redis/",target:"_blank",rel:"noopener noreferrer"},g=i('<h3 id="redis-有哪些应用场景" tabindex="-1"><a class="header-anchor" href="#redis-有哪些应用场景" aria-hidden="true">#</a> Redis 有哪些应用场景</h3><p>【问题】</p><ul><li>Redis 有哪些应用场景？</li></ul><p>【解答】</p><ul><li><strong>缓存</strong> - 将热点数据放到内存中，设置内存的最大使用量以及过期淘汰策略来保证缓存的命中率。</li><li><strong>计数器</strong> - Redis 这种内存数据库能支持计数器频繁的读写操作。</li><li><strong>应用限流</strong> - 限制一个网站访问流量。</li><li><strong>消息队列</strong> - 使用 List 数据类型，它是双向链表。</li><li><strong>查找表</strong> - 使用 HASH 数据类型。</li><li><strong>交集运算</strong> - 使用 SET 类型，例如求两个用户的共同好友。</li><li><strong>排行榜</strong> - 使用 ZSET 数据类型。</li><li><strong>分布式 Session</strong> - 多个应用服务器的 Session 都存储到 Redis 中来保证 Session 的一致性。</li><li><strong>分布式锁</strong> - 除了可以使用 SETNX 实现分布式锁之外，还可以使用官方提供的 RedLock 分布式锁实现。</li></ul><h3 id="redis-vs-memcached" tabindex="-1"><a class="header-anchor" href="#redis-vs-memcached" aria-hidden="true">#</a> Redis vs. Memcached</h3><p>【问题】</p><ul><li>Redis 和 Memcached 有什么相同点？</li><li>Redis 和 Memcached 有什么差异？</li><li>分布式缓存技术选型，选 Redis 还是 Memcached，为什么？</li></ul><p>【解答】</p><p>Redis 与 Memcached 的<strong>共性</strong>：</p><ol><li>都是内存数据库，一般都用来当做缓存使用。</li><li>都有过期策略。</li><li>两者的性能都非常高。</li></ol><p>Redis 与 Memcached 的<strong>差异</strong>：</p><table><thead><tr><th></th><th>Redis</th><th>Memcached</th></tr></thead><tbody><tr><td>数据类型</td><td>支持多种数据类型：String、Hash、List、Set、ZSet 等</td><td>只支持 String 类型</td></tr><tr><td>持久化</td><td>支持两种持久化策略：RDB 和 AOF</td><td>不支持持久化，一旦重启或宕机就会丢失数据</td></tr><tr><td>分布式</td><td>支持分布式</td><td>本身不支持分布式，只能通过在客户端使用像一致性哈希这样的分布式算法来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点</td></tr><tr><td>线程模型</td><td>读写采用单线程+IO 多路复用。因此存储小数据时比 Memcached 性能更高</td><td>采用多线程+IO 多路复用。在 100k 以上的数据中，Memcached 性能要高于 Redis</td></tr><tr><td>其他功能</td><td>支持发布订阅模型、Lua 脚本、事务等功能</td><td>不支持</td></tr></tbody></table><p>通过以上分析，可以看出，Redis 在很多方面都占有优势。因此，绝大多数情况下，优先选择 Redis 作为分布式缓存。</p><blockquote><p>参考：<a href="www.imooc.com/article/23549">《脚踏两只船的困惑 - Memcached 与 Redis》</a></p></blockquote><h3 id="redis-为什么快" tabindex="-1"><a class="header-anchor" href="#redis-为什么快" aria-hidden="true">#</a> Redis 为什么快</h3><p>【问题】</p><ul><li>Redis 有多快？</li><li>Redis 为什么这么快？</li></ul><p>【解答】</p>',19),u={href:"https://redis.io/docs/management/optimization/benchmarks/",target:"_blank",rel:"noopener noreferrer"},h=i('<figure><img src="https://redis.io/docs/management/optimization/benchmarks/Connections_chart.png" alt="Redis 官方 Benchmark QPS 图" tabindex="0" loading="lazy"><figcaption>Redis 官方 Benchmark QPS 图</figcaption></figure><p>Redis 是单线程模型（Redis 6.0 已经支持多线程模型），为什么还能有这么高的并发？</p><ul><li>Redis 读写基于内存</li><li>IO 多路复用 + 读写单线程模型 <ul><li>IO 多路复用是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。</li><li>单线程模型避免了锁竞争的开销</li></ul></li><li>高效的数据结构</li></ul><figure><img src="https://pbs.twimg.com/media/FoYNzdcacAAMjy5?format=jpg&amp;name=4096x4096" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',4),k={href:"https://blog.bytebytego.com/p/why-is-redis-so-fast",target:"_blank",rel:"noopener noreferrer"},R=i('<h2 id="redis-数据类型" tabindex="-1"><a class="header-anchor" href="#redis-数据类型" aria-hidden="true">#</a> Redis 数据类型</h2><h3 id="redis-支持哪些数据类型" tabindex="-1"><a class="header-anchor" href="#redis-支持哪些数据类型" aria-hidden="true">#</a> Redis 支持哪些数据类型</h3><p>【问题】</p><ul><li>Redis 支持哪些数据类型？</li><li>这些数据类型适用于哪些场景？</li></ul><p>【解答】</p><p>Redis 支持五种<strong>基本数据类型</strong>：</p><ul><li><strong>String（字符串）</strong> - 典型应用场景：缓存对象、计数器、分布式锁、共享 Session 信息等。</li><li><strong>Hash（哈希）</strong> - 典型应用场景：缓存对象、购物车等。</li><li><strong>List（列表）</strong> - 典型应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。</li><li><strong>Set（集合）</strong> - 典型应用场景：聚合计算（并集、交集、差集），如点赞、共同关注、抽奖活动等。</li><li><strong>Zset（有序集合）</strong> - 典型应用场景：排序场景，如排行榜、电话和姓名排序等。</li></ul><p>随着版本升级，Redis 支持的四种<strong>扩展数据类型</strong>：</p><ul><li><strong>BitMap</strong>（2.2 版新增） - 二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；</li><li><strong>HyperLogLog</strong>（2.8 版新增） - 海量数据基数统计的场景，比如百万级网页 UV 计数等；</li><li><strong>GEO</strong>（3.2 版新增） - 存储地理位置信息的场景，比如滴滴叫车；</li><li><strong>Stream</strong>（5.0 版新增） - 消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息 ID，支持以消费组形式消费数据。</li></ul><figure><img src="https://global.discourse-cdn.com/standard17/uploads/redis/original/1X/891f134890043da5b983e219c695464e1c4f5c8b.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',10),m={href:"https://forum.redis.com/t/about-redis-commands-data-structures/13",target:"_blank",rel:"noopener noreferrer"},b=i('<h3 id="redis-基本数据类型的底层实现" tabindex="-1"><a class="header-anchor" href="#redis-基本数据类型的底层实现" aria-hidden="true">#</a> Redis 基本数据类型的底层实现</h3><figure><img src="https://cdn.xiaolincoding.com//mysql/other/9fa26a74965efbf0f56b707a03bb9b7f.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="string-类型内部实现" tabindex="-1"><a class="header-anchor" href="#string-类型内部实现" aria-hidden="true">#</a> String 类型内部实现</h4><p>String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）。 SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串：</p><ul><li><strong>SDS 不仅可以保存文本数据，还可以保存二进制数据</strong>。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li><li><strong>SDS 获取字符串长度的时间复杂度是 O(1)</strong>。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。</li><li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li></ul><h4 id="list-类型内部实现" tabindex="-1"><a class="header-anchor" href="#list-类型内部实现" aria-hidden="true">#</a> List 类型内部实现</h4><p>List 类型的底层数据结构是由<strong>双向链表或压缩列表</strong>实现的：</p><ul><li>如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li><li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li></ul><p>但是<strong>在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表</strong>。</p><h4 id="hash-类型内部实现" tabindex="-1"><a class="header-anchor" href="#hash-类型内部实现" aria-hidden="true">#</a> Hash 类型内部实现</h4><p>Hash 类型的底层数据结构是由<strong>压缩列表或哈希表</strong>实现的：</p><ul><li>如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用<strong>压缩列表</strong>作为 Hash 类型的底层数据结构；</li><li>如果哈希类型元素不满足上面条件，Redis 会使用<strong>哈希表</strong>作为 Hash 类型的底层数据结构。</li></ul><p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong>。</p><h4 id="set-类型内部实现" tabindex="-1"><a class="header-anchor" href="#set-类型内部实现" aria-hidden="true">#</a> Set 类型内部实现</h4><p>Set 类型的底层数据结构是由<strong>哈希表或整数集合</strong>实现的：</p><ul><li>如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries 配置）个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li><li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li></ul><h4 id="zset-类型内部实现" tabindex="-1"><a class="header-anchor" href="#zset-类型内部实现" aria-hidden="true">#</a> ZSet 类型内部实现</h4><p>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：</p><ul><li>如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li><li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li></ul><p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></p><h2 id="redis-过期删除和内存淘汰" tabindex="-1"><a class="header-anchor" href="#redis-过期删除和内存淘汰" aria-hidden="true">#</a> Redis 过期删除和内存淘汰</h2><h3 id="redis-过期删除策略" tabindex="-1"><a class="header-anchor" href="#redis-过期删除策略" aria-hidden="true">#</a> Redis 过期删除策略</h3><p>【问题】</p><ul><li>Redis 的过期删除策略是什么？</li></ul><p>【解答】</p><p>Redis 采用的过期策略是：<strong>定期删除+惰性删除</strong>。</p><ul><li><strong>定时删除</strong> - 在设置 key 的过期时间的同时，创建一个定时器，让定时器在 key 的过期时间来临时，立即执行 key 的删除操作。 <ul><li>优点 - 保证过期 key 被尽可能快的删除，释放内存。</li><li>缺点 - <strong>如果过期 key 较多，可能会占用相当一部分的 CPU，从而影响服务器的吞吐量和响应时延</strong>。</li></ul></li><li><strong>惰性删除</strong> - 放任 key 过期不管，但是每次访问 key 时，都检查 key 是否过期，如果过期的话，就删除该 key ；如果没有过期，就返回该 key。 <ul><li>优点 - 占用 CPU 最少。程序只会在读写键时，对当前键进行过期检查，因此不会有额外的 CPU 开销。</li><li>缺点 - <strong>过期的 key 可能因为没有被访问，而一直无法释放，造成内存的浪费，有内存泄漏的风险</strong>。</li></ul></li><li><strong>定期删除</strong> - 每隔一段时间，程序就对数据库进行一次检查，删除里面的过期 key 。至于要删除多少过期 key ，以及要检查多少个数据库，则由算法决定。定期删除是前两种策略的一种折中方案。定期删除策略的难点是删除操作执行的时长和频率。 <ul><li>执行太频或执行时间过长，就会出现和定时删除相同的问题；</li><li>执行太少或执行时间过短，就会出现和惰性删除相同的问题；</li></ul></li></ul><h3 id="持久化时-对过期键会如何处理" tabindex="-1"><a class="header-anchor" href="#持久化时-对过期键会如何处理" aria-hidden="true">#</a> 持久化时，对过期键会如何处理</h3><p>RDB 持久化</p><ul><li><strong>RDB 文件生成阶段</strong> - 从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，<strong>过期的键「不会」被保存到新的 RDB 文件中</strong>，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。</li><li><strong>RDB 加载阶段</strong> - RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况： <ul><li><strong>如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中</strong>。所以过期键不会对载入 RDB 文件的主服务器造成影响；</li><li><strong>如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中</strong>。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。</li></ul></li></ul><p>AOF 持久化</p><ul><li><strong>AOF 文件写入阶段</strong> - 当 Redis 以 AOF 模式持久化时，<strong>如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值</strong>。</li><li><strong>AOF 重写阶段</strong> - 执行 AOF 重写时，会对 Redis 中的键值对进行检查，<strong>已过期的键不会被保存到重写后的 AOF 文件中</strong>，因此不会对 AOF 重写造成任何影响。</li></ul><h3 id="主从复制时-对过期键会如何处理" tabindex="-1"><a class="header-anchor" href="#主从复制时-对过期键会如何处理" aria-hidden="true">#</a> 主从复制时，对过期键会如何处理</h3><p>当 Redis 运行在主从模式下时，<strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</p><p>从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</p><h3 id="redis-内存淘汰策略" tabindex="-1"><a class="header-anchor" href="#redis-内存淘汰策略" aria-hidden="true">#</a> Redis 内存淘汰策略</h3><p>【问题】</p><ul><li>Redis 内存不足时，怎么办？</li><li>Redis 有哪些内存淘汰策略？</li><li>如何选择内存淘汰策略？</li></ul><p>【解答】</p><p>（1）Redis 内存淘汰要点</p><ul><li><strong>失效时间</strong> - 作为一种定期清理无效数据的重要机制，在 Redis 提供的诸多命令中，<code>EXPIRE</code>、<code>EXPIREAT</code>、<code>PEXPIRE</code>、<code>PEXPIREAT</code> 以及 <code>SETEX</code> 和 <code>PSETEX</code> 均可以用来设置一条键值对的失效时间。而一条键值对一旦被关联了失效时间就会在到期后自动删除（或者说变得无法访问更为准确）。</li><li><strong>最大缓存</strong> - Redis 允许通过 <code>maxmemory</code> 参数来设置内存最大值。当内存达设定的阀值，就会触发<strong>内存淘汰</strong>。</li><li><strong>内存淘汰</strong> - 内存淘汰是为了更好的利用内存——清理部分缓存，以此换取内存的利用率，即尽量保证 Redis 缓存中存储的是热点数据。</li></ul><p>（2）Redis 内存淘汰策略</p><ul><li><p><strong>不淘汰</strong></p><ul><li><strong><code>noeviction</code></strong> - 当内存使用达到阈值的时候，所有引起申请内存的命令会报错。这是 Redis 默认的策略。</li></ul></li><li><p><strong>在过期键中进行淘汰</strong></p><ul><li><p><strong><code>volatile-random</code></strong> - 在设置了过期时间的键空间中，随机移除某个 key。</p></li><li><p><strong><code>volatile-ttl</code></strong> - 在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除。</p></li><li><p><strong><code>volatile-lru</code></strong> - 在设置了过期时间的键空间中，优先移除最近未使用的 key。</p></li><li><p><strong><code>volatile-lfu</code></strong> （Redis 4.0 新增）- 淘汰所有设置了过期时间的键值中，最少使用的键值。</p></li></ul></li><li><p><strong>在所有键中进行淘汰</strong></p><ul><li><strong><code>allkeys-lru</code></strong> - 在主键空间中，优先移除最近未使用的 key。</li><li><strong><code>allkeys-random</code></strong> - 在主键空间中，随机移除某个 key。</li><li><strong><code>allkeys-lfu</code></strong> (Redis 4.0 新增) - 淘汰整个键值中最少使用的键值。</li></ul></li></ul><p>（3）如何选择内存淘汰策略</p><ul><li>如果数据呈现幂等分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 <code>allkeys-lru</code> 或 <code>allkeys-lfu</code>。</li><li>如果数据呈现平均分布，也就是所有的数据访问频率都相同，则使用 <code>allkeys-random</code>。</li><li>若 Redis 既用于缓存，也用于持久化存储时，适用 <code>volatile-lru</code> 、<code>volatile-lfu</code>、<code>volatile-random</code>。但是，这种情况下，也可以部署两个 Redis 集群来达到同样目的。</li><li>为 key 设置过期时间实际上会消耗更多的内存。因此，如果条件允许，建议使用 <code>allkeys-lru</code> 或 <code>allkeys-lfu</code>，从而更高效的使用内存。</li></ul><h2 id="redis-持久化" tabindex="-1"><a class="header-anchor" href="#redis-持久化" aria-hidden="true">#</a> Redis 持久化</h2><h3 id="redis-如何保证数据不丢失" tabindex="-1"><a class="header-anchor" href="#redis-如何保证数据不丢失" aria-hidden="true">#</a> Redis 如何保证数据不丢失</h3><p>【问题】</p><ul><li>Redis 如何保证数据不丢失？</li><li>Redis 有几种持久化方式？</li></ul><p>【解答】</p><p>为了追求性能，Redis 的读写都是在内存中完成的。一旦重启，内存中的数据就会清空，为了保证数据不丢失，Redis 支持持久化机制。</p><p>Redis 有三种持久化方式</p><ul><li>RDB 快照</li><li>AOF 日志</li><li>混合持久化</li></ul><h3 id="aof-的实现原理" tabindex="-1"><a class="header-anchor" href="#aof-的实现原理" aria-hidden="true">#</a> AOF 的实现原理</h3><p>【问题】</p><ul><li>AOF 的实现原理是什么？</li><li>为什么先执行命令，再把数据写入日志呢？</li></ul><p>【解答】</p><p>Redis 每执行一条写命令，就会将命令追加写入到一个日志文件中。当重启系统时，可以逐一执行日志中的命令来恢复数据。</p><p>Reids 是先执行写命令，再将该命令记录到 AOF 日志里的，这么做有两个好处。</p><ul><li><strong>避免额外的检查开销</strong>：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。</li><li><strong>不会阻塞当前写操作命令的执行</strong>：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</li></ul><p>当然，这样做也会带来风险：</p><ul><li><strong>数据可能会丢失：</strong> 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。</li><li><strong>可能阻塞其他操作：</strong> 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。</li></ul><h3 id="aof-的回写策略有几种" tabindex="-1"><a class="header-anchor" href="#aof-的回写策略有几种" aria-hidden="true">#</a> AOF 的回写策略有几种</h3><figure><img src="https://cdn.xiaolincoding.com//mysql/other/4eeef4dd1bedd2ffe0b84d4eaa0dbdea-20230309232249413.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ol><li>Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；</li><li>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；</li><li>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</li></ol><p>Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：</p><ul><li><strong>Always</strong>，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li><li><strong>Everysec</strong>，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li><li><strong>No</strong>，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li></ul><h3 id="aof-重写机制" tabindex="-1"><a class="header-anchor" href="#aof-重写机制" aria-hidden="true">#</a> AOF 重写机制</h3><p>【问题】</p><ul><li>AOF 日志过大时，怎么办？</li><li>AOF 重写流程是怎样的？</li><li>AOF 重写时，可以处理请求吗？</li></ul><p>【解答】</p><p>当 AOF 日志过大时，恢复过程就会很久。为了避免此问题，Redis 提供了 AOF 重写机制，即 AOF 日志大小超过所设阈值后，启动 AOF 重写，压缩 AOF 文件。</p><p>AOF 重写机制是，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到新的 AOF 日志中，等到全部记录完成后，就使用新的 AOF 日志替换现有的 AOF 日志。</p><p>Redis 为了在触发 AOF 重写时，依然可以处理请求，会创建一个后台子进程 bgrewriteaof，将 AOF 重写工作交给这个子进程。父子进程间，可以以只读的方式共享内存，但不能修改，这就保证了数据的安全性。<strong>重写过程中，主进程依然可以正常处理命令</strong>。如果此时，主进程收到新的写命令，就会出现数据差异性。为了解决此问题，Redis 设置了一个 AOF 重写缓冲区，在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong>。</p><p>也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:</p><ul><li>执行客户端发来的命令；</li><li>将执行后的写命令追加到 「AOF 缓冲区」；</li><li>将执行后的写命令追加到 「AOF 重写缓冲区」；</li></ul><p>当子进程完成 AOF 重写工作（<em>扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志</em>）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。</p><p>主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：</p><ul><li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；</li><li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</li></ul><p>信号函数执行完后，主进程就可以继续像往常一样处理命令了。</p><h3 id="rdb-的实现原理" tabindex="-1"><a class="header-anchor" href="#rdb-的实现原理" aria-hidden="true">#</a> RDB 的实现原理</h3><p>【问题】</p><ul><li>RDB 的实现原理是什么？</li><li>生成 RDB 快照时，Redis 可以响应请求吗？</li></ul><p>【解答】</p><p>RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。</p><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：</p><ul><li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li><li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li></ul><p>执行 bgsave 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的，关键的技术就在于<strong>写时复制技术（Copy-On-Write, COW）。</strong></p><p>执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。</p><figure><img src="https://cdn.xiaolincoding.com//mysql/other/c34a9d1f58d602ff1fe8601f7270baa7-20230309232304226.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。</p><figure><img src="https://cdn.xiaolincoding.com//mysql/other/ebd620db8a1af66fbeb8f4d4ef6adc68-20230309232308604.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="为什么会有混合持久化" tabindex="-1"><a class="header-anchor" href="#为什么会有混合持久化" aria-hidden="true">#</a> 为什么会有混合持久化？</h3><p>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。</p><p>AOF 优点是丢失数据少，但是数据恢复不快。</p><p>为了集成了两者的优点， Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p><p>混合持久化工作在 <strong>AOF 日志重写过程</strong>，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p><p>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。</p><figure><img src="https://cdn.xiaolincoding.com//mysql/other/f67379b60d151262753fec3b817b8617-20230309232312657.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。</p><p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失</strong>。</p><p><strong>混合持久化优点：</strong></p><ul><li>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</li></ul><p><strong>混合持久化缺点：</strong></p><ul><li>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；</li><li>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</li></ul><h2 id="redis-高可用" tabindex="-1"><a class="header-anchor" href="#redis-高可用" aria-hidden="true">#</a> Redis 高可用</h2><p>【问题】</p><p>Redis 如何保证高可用？</p><h3 id="redis-主从复制" tabindex="-1"><a class="header-anchor" href="#redis-主从复制" aria-hidden="true">#</a> Redis 主从复制</h3><p>【问题】</p><ul><li>Redis 复制的工作原理？Redis 旧版复制和新版复制有何不同？</li><li>Redis 主从节点间如何复制数据？</li><li>Redis 的数据一致性是强一致性吗？</li></ul><p>【解答】</p><p>（1）旧版复制基于 <code>SYNC</code> 命令实现。分为同步（sync）和命令传播（command propagate）两个操作。这种方式存在缺陷：不能高效处理断线重连后的复制情况。</p><p>（2）新版复制基于 <code>PSYNC</code> 命令实现。同步操作分为了两块：</p><ul><li><strong><code>完整重同步（full resychronization）</code></strong> 用于初次复制；</li><li><strong><code>部分重同步（partial resychronization）</code></strong> 用于断线后重复制。 <ul><li>主从服务器的<strong>复制偏移量（replication offset）</strong></li><li>主服务器的<strong>复制积压缓冲区（replication backlog）</strong></li><li><strong>服务器的运行 ID</strong></li></ul></li></ul><p>（3）Redis 集群主从节点复制的工作流程：</p><ul><li>步骤 1. 设置主从服务器</li><li>步骤 2. 主从服务器建立 TCP 连接。</li><li>步骤 3. 发送 PING 检查通信状态。</li><li>步骤 4. 身份验证。</li><li>步骤 5. 发送端口信息。</li><li>步骤 6. 同步。</li><li>步骤 7. 命令传播。</li></ul><p>（4）由于主从复制是<strong>异步</strong>的，具体来说，在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了。所以，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。</p><h3 id="redis-哨兵" tabindex="-1"><a class="header-anchor" href="#redis-哨兵" aria-hidden="true">#</a> Redis 哨兵</h3><p>【问题】</p><ul><li>Redis 哨兵的功能？</li><li>Redis 哨兵的原理？</li><li>Redis 哨兵如何选举 Leader？</li><li>Redis 如何实现故障转移？</li></ul><p>【解答】</p><p>（1）Redis 主从复制模式无法自动故障转移，也就是说，一旦主服务器宕机，需要手动恢复。为了解决此问题，Redis 增加了哨兵模式（Sentinel）。</p><p>（2）由一个或多个 Sentinel 实例组成的 Sentinel 系统可以监视任意多个主服务器，以及这些主服务器的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20200131135847.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="redis-集群" tabindex="-1"><a class="header-anchor" href="#redis-集群" aria-hidden="true">#</a> Redis 集群</h3><p>当 Redis 数据量超出单机的极限，就需要通过分区技术来分而治之。</p><p>Redis 采用的分区策略是：使用虚拟哈希槽来映射节点和数据。在 Redis Cluster 中，为整个集群分配 16384 个哈希槽。每个节点都会被分配一定的哈希槽，这个过程可以是自动分配，也可以是手动分配。任何一个槽没有被分配，那么集群处于下线状态。</p><p>当客户端向服务端发起读写请求时，先要根据 key 计算其所属的哈希槽（计算公式：CRC16(KEY) mod 16384），然后获取该哈希槽所属的节点。这样，就完成了寻址过程。</p><h2 id="redis-脑裂" tabindex="-1"><a class="header-anchor" href="#redis-脑裂" aria-hidden="true">#</a> Redis 脑裂</h2><h3 id="什么是脑裂" tabindex="-1"><a class="header-anchor" href="#什么是脑裂" aria-hidden="true">#</a> 什么是脑裂</h3><p>分布式系统的脑裂问题（Split-Brain Problem）是一个严重的一致性问题，通常发生在分布式系统中的节点之间失去通信或部分通信时。这个问题的名称源自脑裂的比喻，就像一个分布式系统被分成多个部分的&quot;脑&quot;，每个部分独立运行，而没有协调一致的方式。</p><p>脑裂问题通常发生在以下情况下：</p><ol><li><strong>网络分区</strong>：当分布式系统中的网络发生问题，导致节点之间无法互相通信或只能部分通信时。这可能是由于网络故障、硬件故障、防火墙配置问题等原因引起的。</li><li><strong>节点故障</strong>：当分布式系统的某个节点崩溃或出现故障，但其他节点无法确定该节点的状态，可能导致脑裂问题。</li></ol><p>脑裂问题的典型情况是，在网络分区或节点故障后，分布式系统的一部分节点认为另一部分节点已经不可用，因此开始采取某种措施，比如选举新的领袖或切换到备份模式。然而，在某些情况下，网络分区可能会解除，或者节点故障可能会自行修复，导致系统中存在多个独立运行的子系统，每个子系统都认为自己是正确的。</p><p>这种情况下，脑裂问题可能导致以下问题：</p><ol><li><strong>数据不一致性</strong>：不同子系统可能具有不同的数据状态，这可能会导致数据不一致性和冲突。</li><li><strong>资源冲突</strong>：如果不同的子系统尝试访问相同的资源，可能会发生资源冲突和竞争条件。</li><li><strong>性能问题</strong>：系统中的资源可能被多次分配，从而浪费了资源并降低了性能。</li></ol><p>为了解决脑裂问题，分布式系统通常需要采用一些机制，如投票算法、选举协议、心跳检测等，以确保在出现网络分区或节点故障时，系统能够正确地识别和处理问题，并维护一致性。这些机制可以帮助系统中的节点协同工作，避免脑裂问题的发生。然而，脑裂问题是分布式系统设计和管理中的复杂挑战之一，需要细致的规划和测试来确保系统的可靠性和稳定性。</p><h3 id="redis-中的脑裂问题是如何产生的" tabindex="-1"><a class="header-anchor" href="#redis-中的脑裂问题是如何产生的" aria-hidden="true">#</a> Redis 中的脑裂问题是如何产生的</h3><p>在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程 A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。</p><p>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。</p><p>然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。</p><p>总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</p><h3 id="如何解决-redis-中的脑裂问题" tabindex="-1"><a class="header-anchor" href="#如何解决-redis-中的脑裂问题" aria-hidden="true">#</a> 如何解决 Redis 中的脑裂问题</h3><p>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p><p>在 Redis 的配置文件中有两个参数我们可以设置：</p><ul><li><code>min-slaves-to-write x</code>，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li><li><code>min-slaves-max-lag x</code>，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</li></ul><p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。</p><p>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。</p><p>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，<strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。</p><p><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。</strong></p><p>再来举个例子。</p><p>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。</p><p>同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。</p><p>这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p><h2 id="redis-线程模型" tabindex="-1"><a class="header-anchor" href="#redis-线程模型" aria-hidden="true">#</a> Redis 线程模型</h2><h3 id="redis-是单线程吗" tabindex="-1"><a class="header-anchor" href="#redis-是单线程吗" aria-hidden="true">#</a> Redis 是单线程吗？</h3><p><strong>Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的</strong>，这也是我们常说 Redis 是单线程的原因。</p><p>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>（BIO）的：</p><ul><li><strong>Redis 在 2.6 版本</strong>，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；</li><li><strong>Redis 在 4.0 版本之后</strong>，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大 key。</li></ul><p>之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。</p><p>后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/八股文/后台线程.jpg" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列：</p><ul><li>BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭；</li><li>BIO_AOF_FSYNC，AOF 刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘，</li><li>BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象；</li></ul><h3 id="redis-单线程模式是怎样的" tabindex="-1"><a class="header-anchor" href="#redis-单线程模式是怎样的" aria-hidden="true">#</a> Redis 单线程模式是怎样的？</h3><p>Redis 6.0 版本之前的单线模式如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/八股文/redis单线程模型.drawio.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>图中的蓝色部分是一个事件循环，是由主线程负责的，可以看到网络 I/O 和命令处理都是单线程。 Redis 初始化的时候，会做下面这几件事情：</p><ul><li>首先，调用 epoll_create() 创建一个 epoll 对象和调用 socket() 创建一个服务端 socket</li><li>然后，调用 bind() 绑定端口和调用 listen() 监听该 socket；</li><li>然后，将调用 epoll_ctl() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数。</li></ul><p>初始化完后，主线程就进入到一个<strong>事件循环函数</strong>，主要会做以下事情：</p><ul><li>首先，先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li><li>接着，调用 epoll_wait 函数等待事件的到来： <ul><li>如果是<strong>连接事件</strong>到来，则会调用<strong>连接事件处理函数</strong>，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctl 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数；</li><li>如果是<strong>读事件</strong>到来，则会调用<strong>读事件处理函数</strong>，该函数会做这些事情：调用 read 获取客户端发送的数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; 将客户端对象添加到发送队列 -&gt; 将执行结果写到发送缓存区等待发送；</li><li>如果是<strong>写事件</strong>到来，则会调用<strong>写事件处理函数</strong>，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li></ul></li></ul>',172),f={href:"https://mp.weixin.qq.com/s/oeOfsgF-9IOoT5eQt5ieyw",target:"_blank",rel:"noopener noreferrer"},y=i('<h3 id="redis-采用单线程为什么还这么快" tabindex="-1"><a class="header-anchor" href="#redis-采用单线程为什么还这么快" aria-hidden="true">#</a> Redis 采用单线程为什么还这么快？</h3><p>官方使用基准测试的结果是，<strong>单线程的 Redis 吞吐量可以达到 10W/每秒</strong></p><p>之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：</p><ul><li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；</li><li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li><li>Redis 采用了 <strong>I/O 多路复用机制</strong>处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</li></ul><h3 id="redis-6-0-之前为什么使用单线程" tabindex="-1"><a class="header-anchor" href="#redis-6-0-之前为什么使用单线程" aria-hidden="true">#</a> Redis 6.0 之前为什么使用单线程？</h3>',5),v={href:"https://link.juejin.cn/?target=https%3A%2F%2Fredis.io%2Ftopics%2Ffaq",target:"_blank",rel:"noopener noreferrer"},O=i(`<p>核心意思是：<strong>CPU 并不是制约 Redis 性能表现的瓶颈所在</strong>，更多情况下是受到内存大小和网络 I/O 的限制，所以 Redis 核心网络模型使用单线程并没有什么问题，如果你想要使用服务的多核 CPU，可以在一台服务器上启动多个节点或者采用分片集群的方式。</p><p>除了上面的官方回答，选择单线程的原因也有下面的考虑。</p><p>使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，<strong>增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗</strong>。</p><h3 id="redis-6-0-之后为什么引入了多线程" tabindex="-1"><a class="header-anchor" href="#redis-6-0-之后为什么引入了多线程" aria-hidden="true">#</a> Redis 6.0 之后为什么引入了多线程？</h3><p>虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是<strong>在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上</strong>。</p><p>所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。<strong>但是对于命令的执行，Redis 仍然使用单线程来处理，**所以大家**不要误解</strong> Redis 有多线程同时执行命令。</p><p>Redis 官方表示，<strong>Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上</strong>。</p><p>Redis 6.0 版本支持的 I/O 多线程特性，默认情况下 I/O 多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token comment">//读请求也使用io多线程</span>
io<span class="token operator">-</span>threads<span class="token operator">-</span><span class="token keyword">do</span><span class="token operator">-</span>reads yes
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>同时， Redis.conf 配置文件中提供了 IO 多线程个数的配置项。</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token comment">// io-threads N，表示启用 N-1 个 I/O 多线程（主线程也算一个 I/O 线程）</span>
io<span class="token operator">-</span>threads <span class="token number">4</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>关于线程数的设置，官方的建议是如果为 4 核的 CPU，建议线程数设置为 2 或 3，如果为 8 核 CPU 建议线程数设置为 6，线程数一定要小于机器核数，线程数并不是越大越好。</p><p>因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会<strong>额外创建 6 个线程</strong>（<em>这里的线程数不包括主线程</em>）：</p><ul><li>Redis-server ： Redis 的主线程，主要负责执行命令；</li><li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF 刷盘任务、释放内存任务；</li><li>io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力。</li></ul><h2 id="redis-事务" tabindex="-1"><a class="header-anchor" href="#redis-事务" aria-hidden="true">#</a> Redis 事务</h2><p>【问题】</p><ul><li>Redis 的并发竞争问题是什么？如何解决这个问题？</li><li>Redis 支持事务吗？</li><li>Redis 事务是严格意义的事务吗？Redis 为什么不支持回滚。</li><li>Redis 事务如何工作？</li><li>了解 Redis 事务中的 CAS 行为吗？</li></ul><p>【解答】</p><p><strong>Redis 提供的不是严格的事务，Redis 只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去</strong>。</p><p>Redis 不支持回滚的理由：</p><ul><li>Redis 命令只会因为错误的语法而失败，或是命令用在了错误类型的键上面。</li><li>因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。</li></ul><p><code>MULTI</code> 、 <code>EXEC</code> 、 <code>DISCARD</code> 和 <code>WATCH</code> 是 Redis 事务相关的命令。</p><p>Redis 有天然解决这个并发竞争问题的类 CAS 乐观锁方案：每次要<strong>写之前，先判断</strong>一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。</p><h2 id="redis-管道" tabindex="-1"><a class="header-anchor" href="#redis-管道" aria-hidden="true">#</a> Redis 管道</h2><p>【问题】</p><ul><li>除了事务，还有其他批量执行 Redis 命令的方式吗？</li></ul><p>【解答】</p><p>Redis 是一种基于 C/S 模型以及请求/响应协议的 TCP 服务。Redis 支持管道技术。管道技术允许请求以异步方式发送，即旧请求的应答还未返回的情况下，允许发送新请求。这种方式可以大大提高传输效率。使用管道发送命令时，Redis Server 会将部分请求放到缓存队列中（占用内存），执行完毕后一次性发送结果。如果需要发送大量的命令，会占用大量的内存，因此应该按照合理数量分批次的处理。</p><h2 id="redis-应用" tabindex="-1"><a class="header-anchor" href="#redis-应用" aria-hidden="true">#</a> Redis 应用</h2><h3 id="缓存设计" tabindex="-1"><a class="header-anchor" href="#缓存设计" aria-hidden="true">#</a> 缓存设计</h3><h4 id="缓存击穿、缓存穿透、缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存击穿、缓存穿透、缓存雪崩" aria-hidden="true">#</a> 缓存击穿、缓存穿透、缓存雪崩</h4><h4 id="缓存更新" tabindex="-1"><a class="header-anchor" href="#缓存更新" aria-hidden="true">#</a> 缓存更新</h4><h4 id="缓存预热" tabindex="-1"><a class="header-anchor" href="#缓存预热" aria-hidden="true">#</a> 缓存预热</h4><h4 id="缓存数据一致性" tabindex="-1"><a class="header-anchor" href="#缓存数据一致性" aria-hidden="true">#</a> 缓存数据一致性</h4><h4 id="缓存淘汰算法" tabindex="-1"><a class="header-anchor" href="#缓存淘汰算法" aria-hidden="true">#</a> 缓存淘汰算法</h4><p>【问题】</p><p>有哪些常见的内存淘汰算法</p><p>LRU 算法的原理是什么</p><p>LFU 算法的原理是什么</p><h3 id="分布式锁" tabindex="-1"><a class="header-anchor" href="#分布式锁" aria-hidden="true">#</a> 分布式锁</h3><h3 id="大-key-处理" tabindex="-1"><a class="header-anchor" href="#大-key-处理" aria-hidden="true">#</a> 大 Key 处理</h3><h4 id="什么是大-key" tabindex="-1"><a class="header-anchor" href="#什么是大-key" aria-hidden="true">#</a> 什么是大 Key</h4><p>大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。</p><p>一般而言，下面这两种情况被称为大 key：</p><ul><li>String 类型的值大于 10 KB；</li><li>Hash、List、Set、ZSet 类型的元素的个数超过 5000 个；</li></ul><h4 id="大-key-的影响" tabindex="-1"><a class="header-anchor" href="#大-key-的影响" aria-hidden="true">#</a> 大 Key 的影响</h4><p>大 key 会带来以下四种影响：</p><ul><li><strong>客户端超时阻塞</strong>。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li><li><strong>引发网络阻塞</strong>。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li><li><strong>阻塞工作线程</strong>。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li><li><strong>内存分布不均</strong>。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li></ul><h4 id="如何找到大-key" tabindex="-1"><a class="header-anchor" href="#如何找到大-key" aria-hidden="true">#</a> 如何找到大 Key</h4><p><strong><em>1、redis-cli --bigkeys 查找大 key</em></strong></p><p>可以通过 redis-cli --bigkeys 命令查找大 key：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>redis-cli <span class="token parameter variable">-h</span> <span class="token number">127.0</span>.0.1 <span class="token parameter variable">-p6379</span> <span class="token parameter variable">-a</span> <span class="token string">&quot;password&quot;</span> -- bigkeys
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>使用的时候注意事项：</p><ul><li>最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点；</li><li>如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。</li></ul><p>该方式的不足之处：</p><ul><li>这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；</li><li>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大；</li></ul><p><strong><em>2、使用 SCAN 命令查找大 key</em></strong></p><p>使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。</p><p>对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。</p><p>对于集合类型来说，有两种方法可以获得它占用的内存大小：</p><ul><li>如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：<code>LLEN</code> 命令；Hash 类型：<code>HLEN</code> 命令；Set 类型：<code>SCARD</code> 命令；Sorted Set 类型：<code>ZCARD</code> 命令；</li><li>如果不能提前知道写入集合的元素大小，可以使用 <code>MEMORY USAGE</code> 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。</li></ul><p><strong><em>3、使用 RdbTools 工具查找大 key</em></strong></p><p>使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。</p><p>比如，下面这条命令，将大于 10 kb 的 key 输出到一个表格文件。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>rdb dump.rdb <span class="token parameter variable">-c</span> memory <span class="token parameter variable">--bytes</span> <span class="token number">10240</span> <span class="token parameter variable">-f</span> redis.csv
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h4 id="如何删除大-key" tabindex="-1"><a class="header-anchor" href="#如何删除大-key" aria-hidden="true">#</a> 如何删除大 Key</h4><p>如果大 Key 过大，删除时间过长，会阻塞 Redis 主线程，导致主线程无法及时响应其他请求。因此，删除大 Key 时需要考虑分批、异步处理。</p><p><strong><em>1、分批次删除</em></strong></p><p>对于<strong>删除大 Hash</strong>，使用 <code>hscan</code> 命令，每次获取 100 个字段，再用 <code>hdel</code> 命令，每次删除 1 个字段。</p><p>Python 代码：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">del_large_hash</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  r <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">&#39;redis-host1&#39;</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
    large_hash_key <span class="token operator">=</span><span class="token string">&quot;xxx&quot;</span> <span class="token comment">#要删除的大hash键名</span>
    cursor <span class="token operator">=</span> <span class="token string">&#39;0&#39;</span>
    <span class="token keyword">while</span> cursor <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用 hscan 命令，每次获取 100 个字段</span>
        cursor<span class="token punctuation">,</span> data <span class="token operator">=</span> r<span class="token punctuation">.</span>hscan<span class="token punctuation">(</span>large_hash_key<span class="token punctuation">,</span> cursor<span class="token operator">=</span>cursor<span class="token punctuation">,</span> count<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> item <span class="token keyword">in</span> data<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment"># 再用 hdel 命令，每次删除1个字段</span>
                r<span class="token punctuation">.</span>hdel<span class="token punctuation">(</span>large_hash_key<span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于<strong>删除大 List</strong>，通过 <code>ltrim</code> 命令，每次删除少量元素。</p><p>Python 代码：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">del_large_list</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  r <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">&#39;redis-host1&#39;</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
  large_list_key <span class="token operator">=</span> <span class="token string">&#39;xxx&#39;</span>  <span class="token comment">#要删除的大list的键名</span>
  <span class="token keyword">while</span> r<span class="token punctuation">.</span>llen<span class="token punctuation">(</span>large_list_key<span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">:</span>
      <span class="token comment">#每次只删除最右100个元素</span>
      r<span class="token punctuation">.</span>ltrim<span class="token punctuation">(</span>large_list_key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">101</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于<strong>删除大 Set</strong>，使用 <code>sscan</code> 命令，每次扫描集合中 100 个元素，再用 <code>srem</code> 命令每次删除一个键。</p><p>Python 代码：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">del_large_set</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  r <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">&#39;redis-host1&#39;</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
  large_set_key <span class="token operator">=</span> <span class="token string">&#39;xxx&#39;</span>   <span class="token comment"># 要删除的大set的键名</span>
  cursor <span class="token operator">=</span> <span class="token string">&#39;0&#39;</span>
  <span class="token keyword">while</span> cursor <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
    <span class="token comment"># 使用 sscan 命令，每次扫描集合中 100 个元素</span>
    cursor<span class="token punctuation">,</span> data <span class="token operator">=</span> r<span class="token punctuation">.</span>sscan<span class="token punctuation">(</span>large_set_key<span class="token punctuation">,</span> cursor<span class="token operator">=</span>cursor<span class="token punctuation">,</span> count<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> item <span class="token keyword">in</span> data<span class="token punctuation">:</span>
      <span class="token comment"># 再用 srem 命令每次删除一个键</span>
      r<span class="token punctuation">.</span>srem<span class="token punctuation">(</span>large_size_key<span class="token punctuation">,</span> item<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于<strong>删除大 ZSet</strong>，使用 <code>zremrangebyrank</code> 命令，每次删除 top 100 个元素。</p><p>Python 代码：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">del_large_sortedset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  r <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">&#39;large_sortedset_key&#39;</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
  large_sortedset_key<span class="token operator">=</span><span class="token string">&#39;xxx&#39;</span>
  <span class="token keyword">while</span> r<span class="token punctuation">.</span>zcard<span class="token punctuation">(</span>large_sortedset_key<span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">:</span>
    <span class="token comment"># 使用 zremrangebyrank 命令，每次删除 top 100个元素</span>
    r<span class="token punctuation">.</span>zremrangebyrank<span class="token punctuation">(</span>large_sortedset_key<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">99</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong><em>2、异步删除</em></strong></p><p>从 Redis 4.0 版本开始，可以采用<strong>异步删除</strong>法，<strong>用 unlink 命令代替 del 来删除</strong>。</p><p>这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。</p><p>除了主动调用 unlink 命令实现异步删除之外，我们还可以通过配置参数，达到某些条件的时候自动进行异步删除。</p><p>主要有 4 种场景，默认都是关闭的：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del
noslave-lazy-flush no
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>它们代表的含义如下：</p><ul><li>lazyfree-lazy-eviction：表示当 Redis 运行内存超过 maxmeory 时，是否开启 lazy free 机制删除；</li><li>lazyfree-lazy-expire：表示设置了过期时间的键值，当过期之后是否开启 lazy free 机制删除；</li><li>lazyfree-lazy-server-del：有些指令在处理已存在的键时，会带有一个隐式的 del 键的操作，比如 rename 命令，当目标键已存在，Redis 会先删除目标键，如果这些目标键是一个 big key，就会造成阻塞删除的问题，此配置表示在这种场景中是否开启 lazy free 机制删除；</li><li>slave-lazy-flush：针对 slave (从节点) 进行全量数据同步，slave 在加载 master 的 RDB 文件前，会运行 flushall 来清理自己的数据，它表示此时是否开启 lazy free 机制删除。</li></ul><p>建议开启其中的 lazyfree-lazy-eviction、lazyfree-lazy-expire、lazyfree-lazy-server-del 等配置，这样就可以有效的提高主线程的执行效率。</p><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料" aria-hidden="true">#</a> 参考资料</h2>`,90),x={href:"https://juejin.im/post/5ad6e4066fb9a028d82c4b66",target:"_blank",rel:"noopener noreferrer"},_={href:"https://github.com/doocs/advanced-java#%E7%BC%93%E5%AD%98",target:"_blank",rel:"noopener noreferrer"},A={href:"https://xiaolincoding.com/redis/base/redis_interview.html",target:"_blank",rel:"noopener noreferrer"};function F(S,D){const n=r("ExternalLinkIcon");return l(),o("div",null,[p,s("p",null,[e("图来自 "),s("a",c,[e("https://architecturenotes.co/redis/"),a(n)])]),g,s("p",null,[e("根据 "),s("a",u,[e("Redis 官方 Benchmark"),a(n)]),e(" 文档的描述，Redis 单机 QPS 能达到 10w+。")]),h,s("p",null,[e("图来自 "),s("a",k,[e("Why is redis so fast?"),a(n)])]),R,s("p",null,[e("图来自 "),s("a",m,[e("https://forum.redis.com/t/about-redis-commands-data-structures/13"),a(n)])]),b,s("p",null,[e("以上就是 Redis 单线模式的工作方式，如果你想看源码解析，可以参考这一篇："),s("a",f,[e("为什么单线程的 Redis 如何做到每秒数万 QPS ？(opens new window)"),a(n)])]),y,s("p",null,[e("我们都知道单线程的程序是无法利用服务器的多核 CPU 的，那么早期 Redis 版本的主要工作（网络 I/O 和执行命令）为什么还要使用单线程呢？我们不妨先看一下 Redis 官方给出的"),s("a",v,[e("FAQ (opens new window)"),a(n)]),e("。")]),O,s("ul",null,[s("li",null,[s("a",x,[e("面试中关于 Redis 的问题看这篇就够了"),a(n)])]),s("li",null,[s("a",_,[e("advanced-java"),a(n)])]),s("li",null,[s("a",A,[e("Redis 常见面试题"),a(n)])])])])}const B=t(d,[["render",F],["__file","01.Redis面试.html.vue"]]);export{B as default};
